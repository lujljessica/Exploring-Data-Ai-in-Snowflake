{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snowflake connector\n",
    "from snowflake import connector\n",
    "#from snowflake.ml.utils import connection_params\n",
    "\n",
    "# Snowpark for Python\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import Variant\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.snowpark import functions as F\n",
    "from snowflake.snowpark.types import *\n",
    "\n",
    "# Snowpark ML\n",
    "from snowflake.ml.modeling.compose import ColumnTransformer\n",
    "from snowflake.ml.modeling.pipeline import Pipeline\n",
    "from snowflake.ml.modeling.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from snowflake.ml.modeling.impute import SimpleImputer\n",
    "from snowflake.ml.modeling.model_selection import GridSearchCV\n",
    "from snowflake.ml.modeling.xgboost import XGBRegressor\n",
    "from snowflake.ml import version\n",
    "mlversion = version.VERSION\n",
    "from snowflake.ml.registry import Registry\n",
    "\n",
    "#Feature Store\n",
    "from snowflake.ml.feature_store import FeatureStore, CreationMode, Entity, FeatureView\n",
    "\n",
    "# Misc\n",
    "import pandas as pd\n",
    "import json\n",
    "import logging \n",
    "logger = logging.getLogger(\"snowflake.snowpark.session\")\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "import sys\n",
    "print(sys.version) ##Last run used Python 3.11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Date feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from snowflake.ml.feature_store import FeatureStore, CreationMode, Entity, FeatureView\n",
    "\n",
    "from snowflake.snowpark.functions import col, dayofmonth, dayofweek, month, weekofyear, quarter, year, last_day, when, lit\n",
    "import snowflake.snowpark as snowpark\n",
    "from snowflake.snowpark import Session\n",
    "# Generate the DataFrame\n",
    "session = get_active_session()\n",
    "\n",
    "\n",
    "fs = FeatureStore(\n",
    "    session=session,\n",
    "    database=\"RETAIL_DEMO\",\n",
    "    name=\"FEATURE_STORE_MLDEMO\",\n",
    "    default_warehouse=\"\", # edit\n",
    "    creation_mode=CreationMode.CREATE_IF_NOT_EXIST,\n",
    ")\n",
    "\n",
    "entity = Entity(\n",
    "    name=\"Date_features\",\n",
    "    join_keys=[\"DATE\"],\n",
    ")\n",
    "fs.register_entity(entity)\n",
    "\n",
    "#Show the entities\n",
    "fs.list_entities().show()\n",
    "\n",
    "df = session.range(2192).select(\n",
    "    (col(\"id\") + lit(1)).cast(\"int\").alias(\"SEQ4\")\n",
    ").select(\n",
    "    (lit(\"2020-01-01\").cast(\"date\") + col(\"SEQ4\")).alias(\"DATE\")\n",
    ").select(\n",
    "    col(\"DATE\"),\n",
    "    dayofmonth(col(\"DATE\")).alias(\"day_of_month\"),\n",
    "    dayofweek(col(\"DATE\")).alias(\"day_of_week\"),\n",
    "    month(col(\"DATE\")).alias(\"month_number\"),\n",
    "    weekofyear(col(\"DATE\")).alias(\"week_of_year\"),\n",
    "    quarter(col(\"DATE\")).alias(\"quarter_number\"),\n",
    "    year(col(\"DATE\")).alias(\"year_number\"),\n",
    "    when((dayofweek(col(\"DATE\")) == 6) | (dayofweek(col(\"DATE\")) == 0), 1).otherwise(0).alias(\"IS_WEEKEND\"),\n",
    "    when(col(\"DATE\") == last_day(col(\"DATE\")), 1).otherwise(0).alias(\"is_last_day\")\n",
    ")\n",
    "\n",
    "date_fv = = FeatureView(\n",
    "    name=\"DateFeatures\",\n",
    "    entities=[entity],\n",
    "    feature_df= df,\n",
    "    timestamp_col=\"DATE\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.functions import col, to_timestamp, dayofweek, month,sum, listagg, lag\n",
    "from snowflake.snowpark import Window\n",
    "\n",
    "df = df.with_column('DATE', to_timestamp(col('DATE'), 'MM/DD/YYYY'))\n",
    "\n",
    "# Add a new column for the day of the week\n",
    "# The day of week is represented as an integer, with 0 = Sunday, 1 = Monday, ..., 6 = Saturday\n",
    "df = df.with_column('DAY_OF_WEEK', dayofweek(col('DATE')))\n",
    "\n",
    "\n",
    "# Add a new column for the month\n",
    "df = df.with_column('MONTH', month(col('DATE')))\n",
    "\n",
    "# Group by DATE, DAY_OF_WEEK, and MONTH, then aggregate\n",
    "total_riders = df.group_by('DATE','DAY_OF_WEEK','MONTH').agg(\n",
    "    F.listagg('DAYTYPE', is_distinct=True).alias('DAYTYPE'),\n",
    "    F.sum('RIDES').alias('TOTAL_RIDERS')\n",
    ").order_by('DATE')\n",
    "'''\n",
    "Adding Lags\n",
    "'''\n",
    "#Define a window specification\n",
    "window_spec = Window.order_by('DATE')\n",
    "\n",
    "# Add a lagged column for total ridership of the previous day\n",
    "total_riders = total_riders.with_column('PREV_DAY_RIDERS', lag(col('TOTAL_RIDERS'), 1).over(window_spec))\n",
    "\n",
    "# Show the resulting dataframe\n",
    "print (total_riders.count())\n",
    "print (total_riders.show())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create aggregated view of data as a feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_fv = FeatureView(\n",
    "    name=\"AggBusData\",\n",
    "    entities=[entity],\n",
    "    feature_df=total_riders,\n",
    "    timestamp_col=\"DATE\",\n",
    ")\n",
    "\n",
    "agg_fv = fs.register_feature_view(agg_fv, version=\"1\", overwrite=True)\n",
    "\n",
    "# Show our newly created Feature View and display as Pandas DataFrame\n",
    "fs.list_feature_views().to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date range between 2017 and 2019\n",
    "date_range = pd.date_range(start='01/01/2013', end='12/31/2019')\n",
    "date_column = date_range.strftime('%m/%d/%Y')\n",
    "df = pd.DataFrame(date_column, columns=['DATE'])\n",
    "spine_df = session.create_dataframe(df)\n",
    "\n",
    "training_set = fs.generate_training_set(\n",
    "    spine_df=spine_df,\n",
    "    features=[agg_fv])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## Distributed Preprocessing - 25X to 50X faster\n",
    "numeric_features = ['DAY_OF_WEEK','MONTH','PREV_DAY_RIDERS','MINIMUM_TEMPERATURE','MAXIMUM_TEMPERATURE','PRECIPITATION']\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "categorical_cols = ['DAYTYPE']\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-99999))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "        ])\n",
    "\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor),('model', XGBRegressor())])\n",
    "\n",
    " ## Distributed HyperParameter Optimization\n",
    "hyper_param = dict(\n",
    "        model__max_depth=[2,4],\n",
    "        model__learning_rate=[0.1,0.3],\n",
    "    )\n",
    "\n",
    "xg_model = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=hyper_param,\n",
    "    #cv=5,\n",
    "    input_cols=numeric_features + categorical_cols,\n",
    "    label_cols=['TOTAL_RIDERS'],\n",
    "    output_cols=[\"TOTAL_RIDERS_FORECAST\"],\n",
    ")\n",
    "\n",
    "# Fit and Score\n",
    "xg_model.fit(train)\n",
    "##Takes 25 seconds\n",
    "\n",
    "testpreds = xg_model.predict(test)\n",
    "print('MSE:', mean_absolute_error(df=testpreds, y_true_col_names='TOTAL_RIDERS', y_pred_col_names='\"TOTAL_RIDERS_FORECAST\"'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
